# pip install google-generativeai mcp
import asyncio
import os
# Add json import for formatting output
import json
from datetime import datetime
from google import genai
from google.genai import types
from mcp import ClientSession, StdioServerParameters
from mcp.client.stdio import stdio_client
import argparse

parser = argparse.ArgumentParser(description="Example: list of ids")

# nargs="+" means one or more arguments
parser.add_argument(
    "--items",
    nargs="+",
    type=str,
    help="A list of ids"
)
parser.add_argument(
    "--filename",
    type=str,
)


client = genai.Client(api_key=os.getenv("GEMINI_API_KEY"))

# Re-add StdioServerParameters, setting args for stdio
server_params = StdioServerParameters(
    command="python",
    args=["jupiter_mcp.py"],
)

async def runJ(id_list):
    # Remove debug prints
    async with stdio_client(server_params) as (read, write):
        async with ClientSession(read, write) as session:
            prompt = f"Find the prices of the tokens with ids {id_list} using the tool call given"
            await session.initialize()
            # Remove debug prints

            mcp_tools = await session.list_tools()
            # Remove debug prints
            tools = [
                types.Tool(
                    function_declarations=[
                        {
                            "name": tool.name,
                            "description": tool.description,
                            "parameters": {
                                k: v
                                for k, v in tool.inputSchema.items()
                                if k not in ["additionalProperties", "$schema"]
                            },
                        }
                    ]
                )
                for tool in mcp_tools.tools
            ]
            # Remove debug prints

            response = client.models.generate_content(
                model="gemini-2.5-flash-lite",
                contents=prompt,
                config=types.GenerateContentConfig(
                    temperature=0,
                    tools=tools,
                ),
            )

            # Remove raw response print
            if response.candidates[0].content.parts[0].function_call:
                function_call = response.candidates[0].content.parts[0].function_call

                result = await session.call_tool(
                    function_call.name, arguments=dict(function_call.args)
                )
                try:
                    price = json.loads(result.content[0].text)
                    return(price)
                except json.JSONDecodeError:
                    print("MCP server returned non-JSON response:")
                    return result.content[0].text
                except (IndexError, AttributeError):
                     print("Unexpected result structure from MCP server:")
                     return result
            else:
                print("No function call was generated by the model.")
                if response.text:
                     print("Model response:")
                     return response.text

# Re-add StdioServerParameters, setting args for stdio
server_params2 = StdioServerParameters(
    command="python",
    args=["vybe_mcp.py"],
)

async def runV(id):
    async with stdio_client(server_params2) as (read, write):
        async with ClientSession(read, write) as session:
            prompt = f"Get the price history of the token with ids {id}"
            await session.initialize()

            # List tools
            mcp_tools = await session.list_tools()
            tools = [
                types.Tool(
                    function_declarations=[
                        {
                            "name": tool.name,
                            "description": tool.description,
                            "parameters": {
                                k: v
                                for k, v in tool.inputSchema.items()
                                if k not in ["additionalProperties", "$schema"]
                            },
                        }
                    ]
                )
                for tool in mcp_tools.tools
            ]

            # 1️⃣ Generate initial response
            response = client.models.generate_content(
                model="gemini-2.5-flash-lite",
                contents=prompt,
                config=types.GenerateContentConfig(
                    temperature=0,
                    tools=tools,
                ),
            )

            # 2️⃣ Check if a function call was generated
            try:
                func_call = response.candidates[0].content.parts[0].function_call
            except (IndexError, AttributeError):
                func_call = None

            final_response_text = None

            if func_call:
                # 3️⃣ Call the tool
                tool_result = await session.call_tool(
                    func_call.name, arguments=dict(func_call.args)
                )

                # Try to extract text from tool result
                try:
                    tool_output = tool_result.content[0].text
                except (IndexError, AttributeError):
                    tool_output = str(tool_result)

                # 4️⃣ Feed the tool result back to the AI
                followup_prompt = (
                    f"The tool `{func_call.name}` returned the following result:\n"
                    f"{tool_output}\n\n"
                    f"Please provide the simple final HTML-renderable chart based on this data. The chart should be easily understandable and addable to any HTML file."
                )

                final_response = client.models.generate_content(
                    model="gemini-2.5-flash",
                    contents=followup_prompt,
                    config=types.GenerateContentConfig(temperature=0),
                )

                # Only print the last AI response
                final_response_text = getattr(final_response, "text", None)

            else:
                # No function call; just use the original response
                final_response_text = getattr(response, "text", None)

            if final_response_text:
                return final_response_text
            else:
                return "No final response generated."


async def mainAI(ids, filename):
    prices = await runJ(ids)
    chart = await runV(ids[0])

    system_prompt = """
    You are a modern built tool for efficiency and saving people time within the financial market. Your task is to generate a professional HTML-formatted email summarizing the current prices and trends of the specific cryptocurrencies provided. Follow these instructions:

    Format:

    The output must be a fully written HTML email, including:

    <html>, <head>, <body> tags

    A TL;DR one-sentence summary at the top of the body

    Body with key price data, trends, and brief commentary in a readable HTML structure (tables or bullet points)

    Closing

    Content Requirements:

    Include name, current price, 24-hour high, 24-hour low, and 24-hour percentage change for each cryptocurrency.

    Include a brief trend analysis for each coin (bullish, bearish, sideways) based on the 24-hour change.

    Include a short overall market summary if relevant.

    Round numeric values to 2 decimal places.

    Style:

    Use HTML elements for readability:

    <table> or <ul>/<li> for listing cryptocurrencies

    <strong> for emphasis (e.g., coin name, price)

    Optional inline styles for colors: green for positive change, red for negative change

    YOUR RESPONSE MUST NOT CONTAIN ANY COMMENTS OR ANY OTHER TEXT AND MUST BE COMPLETELY RENDERABLE HTML ONLY!!

    Example HTML structure:
    
<html>
  <body>
    <p>Hi [Recipient Name],</p>

    <p><strong>TL;DR:</strong> coinA and coinB are showing bullish trends, while some altcoins have seen minor declines in the last 24 hours.</p>

    <table border="1" cellpadding="5" cellspacing="0">
      <tr>
        <th>Coin</th>
        <th>Price</th>
        <th>High (24h)</th>
        <th>Low (24h)</th>
        <th>24h Change</th>
        <th>Trend</th>
      </tr>

      [Chart Rendering Included Here]

      <tr>
        <td>A</td>
        <td>$XX,XXX.XX</td>
        <td>$XX,XXX.XX</td>
        <td>$XX,XXX.XX</td>
        <td style="color:green;">+X.XX%</td>
        <td>Bullish</td>
      </tr>
      <tr>
        <td>B</td>
        <td>$X,XXX.XX</td>
        <td>$X,XXX.XX</td>
        <td>$X,XXX.XX</td>
        <td style="color:red;">-X.XX%</td>
        <td>Bearish</td>
      </tr>
      <!-- Additional coins here -->
    </table>

    <p>Overall, the market shows a [general trend] today, with [brief commentary].</p>

    <p>Solvend, 2025</p>
  </body>
</html>

Here are a few prices and the charts you must include in the response:
"""
    system_prompt += str(prices)
    system_prompt += str(chart)
    response = client.models.generate_content(
        model="gemini-2.5-flash",
        contents=system_prompt,
    )
    with open(f"{filename}.html", "w") as f:
        f.write(response.text)


# Revert main block
args = parser.parse_args()
asyncio.run(mainAI(args.items, args.filename))